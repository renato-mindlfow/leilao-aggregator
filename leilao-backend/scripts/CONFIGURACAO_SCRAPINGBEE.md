# üîë Configura√ß√£o do ScrapingBee no Projeto

## üìç Onde o ScrapingBee est√° configurado

### 1. **Arquivo Principal: `app/utils/fetcher.py`**
   - Classe: `MultiLayerFetcher`
   - Linha 46: `self.scrapingbee_api_key = scrapingbee_api_key or os.getenv("SCRAPINGBEE_API_KEY")`
   - Usado como **Camada 3** de fallback para bypass de prote√ß√µes anti-bot

### 2. **Script de Download Caixa: `scripts/download_caixa_scrapingbee.py`**
   - Linha 16: `SCRAPINGBEE_API_KEY = os.getenv("SCRAPINGBEE_API_KEY")`
   - Carrega via `load_dotenv()` se dispon√≠vel

### 3. **Deploy Script: `scripts/deploy.sh`**
   - Linhas 38-40: Configura secret no Fly.io se presente no `.env`

## üîç Status Atual

**‚ùå API Key N√ÉO encontrada localmente:**
- Arquivo `.env` existe mas n√£o cont√©m `SCRAPINGBEE_API_KEY`
- Vari√°vel de ambiente n√£o est√° configurada

## ‚úÖ Como Configurar

### Op√ß√£o 1: Arquivo `.env` (Recomendado para desenvolvimento)

Edite `leilao-aggregator-git/leilao-backend/.env` e adicione:

```env
SCRAPINGBEE_API_KEY=sua-chave-aqui
```

### Op√ß√£o 2: Vari√°vel de Ambiente (Windows PowerShell)

```powershell
$env:SCRAPINGBEE_API_KEY="sua-chave-aqui"
```

### Op√ß√£o 3: Vari√°vel de Ambiente (Linux/Mac)

```bash
export SCRAPINGBEE_API_KEY="sua-chave-aqui"
```

### Op√ß√£o 4: Fly.io Secrets (Produ√ß√£o)

Se a API key estiver configurada no Fly.io como secret, ela estar√° dispon√≠vel em produ√ß√£o, mas n√£o localmente.

Para verificar secrets do Fly.io:
```bash
flyctl secrets list --app leilao-backend-solitary-haze-9882
```

Para configurar:
```bash
flyctl secrets set SCRAPINGBEE_API_KEY="sua-chave" --app leilao-backend-solitary-haze-9882
```

## üß™ Teste

Ap√≥s configurar, teste com:

```bash
cd leilao-aggregator-git/leilao-backend
python scripts/download_caixa_scrapingbee.py
```

## üìù Notas

- O projeto usa `python-dotenv` para carregar `.env` automaticamente
- A API key √© usada em m√∫ltiplos lugares:
  - `fetcher.py` (camada 3 de fallback)
  - `download_caixa_scrapingbee.py` (download de CSVs da Caixa)
- Se n√£o configurada, o sistema continua funcionando mas sem acesso ao ScrapingBee

