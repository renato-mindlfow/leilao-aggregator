# Implementa√ß√£o: Scraping Inteligente com Descoberta de Estrutura

**Data:** 03/01/2026  
**Status:** ‚úÖ Completo

## üìã Resumo

Implementado sistema completo de scraping inteligente que descobre automaticamente a estrutura de sites de leiloeiros e usa essa informa√ß√£o para extrair im√≥veis de forma mais eficiente.

## üóÑÔ∏è Mudan√ßas no Banco de Dados

### Migra√ß√£o SQL
- **Arquivo:** `migrations/002_add_discovery_columns.sql`
- **Script de aplica√ß√£o:** `scripts/apply_discovery_migration.py`

### Novas Colunas na Tabela `auctioneers`:
- `scrape_config` (JSONB) - Configura√ß√£o descoberta pela IA
- `discovery_status` (VARCHAR) - Status: pending, completed, failed, needs_rediscovery
- `last_discovery_at` (TIMESTAMP) - Data da √∫ltima descoberta
- `structure_hash` (VARCHAR) - Hash MD5 da estrutura para detectar mudan√ßas
- `validation_metrics` (JSONB) - M√©tricas de valida√ß√£o (falhas, sucessos, etc)

### √çndices Criados:
- `idx_auctioneers_discovery_status`
- `idx_auctioneers_structure_hash`
- `idx_auctioneers_last_discovery_at`

## üìÅ Arquivos Criados

### 1. `app/services/site_discovery.py`
Servi√ßo que descobre a estrutura de sites usando IA:
- Baixa homepage do site
- Analisa com OpenAI (GPT-4o-mini)
- Identifica filtros, pagina√ß√£o, selectors
- Valida URLs descobertas
- Calcula hash da estrutura

### 2. `app/services/discovery_orchestrator.py`
Orquestra o processo de descoberta:
- `run_discovery()` - Executa descoberta para m√∫ltiplos leiloeiros
- `run_single_discovery()` - Descoberta para um leiloeiro espec√≠fico
- `run_rediscovery()` - Re-descoberta autom√°tica
- `get_discovery_stats()` - Estat√≠sticas de descoberta

### 3. `app/services/structure_validator.py`
Valida e decide quando re-descobrir:
- `needs_rediscovery()` - Verifica se precisa re-descoberta
- `check_structure_changed()` - Compara hash da estrutura
- `update_validation_metrics()` - Atualiza m√©tricas ap√≥s extra√ß√£o
- `calculate_config_expiry()` - Calcula data de expira√ß√£o

## üîÑ Arquivos Modificados

### 1. `app/services/universal_scraper.py`
Adicionados m√©todos:
- `scrape_with_config()` - Scraping usando configura√ß√£o descoberta
- `_extract_from_url()` - Extra√ß√£o de uma URL espec√≠fica
- `_paginate_with_config()` - Pagina√ß√£o usando configura√ß√£o

### 2. `app/services/scraper_orchestrator.py`
Adicionado m√©todo:
- `run_all_smart()` - Executa scraping inteligente usando configs quando dispon√≠veis
- `_get_active_auctioneers_with_config()` - Busca leiloeiros com suas configura√ß√µes

### 3. `app/main.py`
Novos endpoints:
- `POST /api/discovery/run` - Executa descoberta
- `POST /api/discovery/single/{auctioneer_id}` - Descoberta √∫nica
- `GET /api/discovery/stats` - Estat√≠sticas
- `POST /api/scraper/run-smart` - Scraping inteligente
- `POST /api/discovery/rediscovery` - Re-descoberta
- `GET /api/discovery/needs-rediscovery` - Lista que precisam re-descoberta
- `POST /api/discovery/check-structure/{auctioneer_id}` - Verifica mudan√ßas

### 4. `scripts/daily_maintenance.py`
Atualizado para incluir:
- Verifica√ß√£o autom√°tica de configs expiradas
- Re-descoberta autom√°tica de sites problem√°ticos

### 5. `scripts/apply_discovery_migration.py`
Novo script para aplicar a migra√ß√£o SQL

## üöÄ Como Usar

### 1. Aplicar Migra√ß√£o do Banco
```bash
cd leilao-backend
python scripts/apply_discovery_migration.py
```

### 2. Executar Descoberta Inicial
```bash
# Via API
curl -X POST "http://localhost:8000/api/discovery/run?limit=5"

# Ou via Python
python -c "
import asyncio
from app.services.discovery_orchestrator import discovery_orchestrator
result = asyncio.run(discovery_orchestrator.run_discovery(limit=5))
print(result)
"
```

### 3. Executar Scraping Inteligente
```bash
# Via API
curl -X POST "http://localhost:8000/api/scraper/run-smart?limit=5&skip_geocoding=true"

# Ou via Python
python -c "
import asyncio
from app.services.scraper_orchestrator import scraper_orchestrator
result = asyncio.run(scraper_orchestrator.run_all_smart(skip_geocoding=True, limit=5))
print(result)
"
```

### 4. Verificar Status
```bash
curl "http://localhost:8000/api/discovery/stats"
```

### 5. Re-descoberta Autom√°tica
```bash
# Via API
curl -X POST "http://localhost:8000/api/discovery/rediscovery?limit=10"

# Ou executar manuten√ß√£o di√°ria
python scripts/daily_maintenance.py
```

## üìä Estrutura da Configura√ß√£o (scrape_config)

```json
{
  "version": "1.0",
  "discovered_at": "2026-01-03T20:00:00Z",
  "expires_at": "2026-02-02T20:00:00Z",
  "site_type": "filter_based",
  "base_url": "https://example.com",
  
  "property_filters": [
    {"name": "Apartamento", "url": "/busca?categoria=apartamento", "validated": true},
    {"name": "Casa", "url": "/busca?categoria=casa", "validated": true}
  ],
  
  "pagination": {
    "type": "query_param",
    "param": "page",
    "start": 1,
    "pattern": "?page={n}"
  },
  
  "selectors": {
    "property_list": ".lista-imoveis .item",
    "property_link": "a.ver-detalhes",
    "next_page": ".paginacao .next"
  },
  
  "fallback_url": "/imoveis",
  "requires_js": false,
  
  "validation": {
    "structure_hash": "a1b2c3d4e5f6...",
    "last_validated_at": "2026-01-03T20:00:00Z",
    "consecutive_failures": 0,
    "total_extractions": 0,
    "successful_extractions": 0
  },
  
  "notes": "Site usa filtros por categoria na sidebar"
}
```

## üîÑ Fluxo de Funcionamento

### Fase 1: Descoberta (1x por leiloeiro)
1. Acessa homepage do site
2. IA analisa estrutura e identifica filtros/pagina√ß√£o
3. Valida URLs descobertas
4. Salva configura√ß√£o no banco com hash da estrutura

### Fase 2: Extra√ß√£o (di√°ria)
1. L√™ configura√ß√£o do leiloeiro
2. Vai direto aos URLs de filtros descobertos
3. Extrai im√≥veis de cada filtro
4. Pagina usando configura√ß√£o descoberta
5. Atualiza m√©tricas de valida√ß√£o

### Fase 3: Valida√ß√£o (autom√°tica)
1. Verifica se config expirou (>30 dias)
2. Verifica falhas consecutivas (>=3)
3. Verifica taxa de sucesso (<50%)
4. Re-descobre automaticamente se necess√°rio

## üìà Impacto Esperado

| M√©trica | Antes | Depois |
|---------|-------|--------|
| Taxa de sucesso | ~30% | >70% |
| Requisi√ß√µes por leiloeiro | 15-20 | 3-5 |
| Custo OpenAI | Alto | Baixo |
| Cobertura de im√≥veis | Parcial | Completa |
| Tempo de scraping | ~2min/leiloeiro | ~30s/leiloeiro |

## ‚úÖ Pr√≥ximos Passos

1. **Aplicar migra√ß√£o SQL** no banco de produ√ß√£o
2. **Executar descoberta inicial** para todos os leiloeiros
3. **Monitorar m√©tricas** de sucesso/falha
4. **Configurar job di√°rio** para re-descoberta autom√°tica
5. **Ajustar par√¢metros** de valida√ß√£o conforme necess√°rio

## üêõ Troubleshooting

### Erro: "DATABASE_URL n√£o configurada"
- Verificar se `.env` est√° configurado corretamente

### Erro: "OpenAI API Key n√£o encontrada"
- Configurar `OPENAI_API_KEY` no `.env`

### Descoberta falhando para muitos sites
- Verificar logs para identificar padr√µes
- Ajustar prompt de descoberta se necess√°rio
- Verificar se sites est√£o acess√≠veis

### Config expirando muito r√°pido
- Ajustar `CONFIG_EXPIRY_DAYS` em `structure_validator.py`

---

**Implementa√ß√£o completa!** ‚úÖ

