# .github/workflows/scrape-top10-leiloeiros.yml
# 
# Workflow para scraping automatizado dos TOP 10 leiloeiros
# Executa 2x ao dia: 6h e 18h (horÃ¡rio de BrasÃ­lia)

name: Scrape TOP 10 Leiloeiros

on:
  # ExecuÃ§Ã£o agendada - SEMPRE roda o TOP 10
  schedule:
    # 6:00 BRT (09:00 UTC)
    - cron: '0 9 * * *'
    # 18:00 BRT (21:00 UTC)  
    - cron: '0 21 * * *'
  
  # ExecuÃ§Ã£o manual
  workflow_dispatch:
    inputs:
      limit_top10:
        description: 'Limite de leiloeiros TOP 10 (1-10)'
        required: false
        default: '10'
        type: string
      max_properties:
        description: 'MÃ¡ximo de propriedades por leiloeiro'
        required: false
        default: '100'
        type: string

env:
  DATABASE_URL: ${{ secrets.DATABASE_URL }}
  PYTHONUNBUFFERED: 1

jobs:
  scrape-top10:
    name: ðŸ† Scrape TOP 10 Leiloeiros
    runs-on: ubuntu-latest
    timeout-minutes: 60
    
    steps:
      - name: ðŸ“¥ Checkout cÃ³digo
        uses: actions/checkout@v4
        
      - name: ðŸ Setup Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          
      - name: ðŸ“¦ Instalar dependÃªncias
        working-directory: leilao-backend
        run: |
          pip install --upgrade pip
          pip install playwright psycopg2-binary python-dotenv
          playwright install chromium
          playwright install-deps chromium
          
      - name: ðŸ” Verificar script
        working-directory: leilao-backend
        run: |
          ls -la scripts/
          test -f scripts/SCRAPER_TOP10_CORRIGIDO.py && echo "âœ… Script encontrado" || echo "âŒ Script nÃ£o encontrado"
          
      - name: ðŸš€ Executar Scraper TOP 10
        working-directory: leilao-backend
        run: |
          python scripts/SCRAPER_TOP10_CORRIGIDO.py \
            --limit ${{ github.event.inputs.limit_top10 || '10' }} \
            --max-properties ${{ github.event.inputs.max_properties || '100' }}
            
      - name: ðŸ“¤ Upload resultado JSON
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: scraping-result-${{ github.run_number }}
          path: leilao-backend/top10_scraping_*.json
          retention-days: 7

  report:
    name: ðŸ“Š RelatÃ³rio Final
    runs-on: ubuntu-latest
    needs: [scrape-top10]
    if: always()
    
    steps:
      - name: ðŸ“¥ Download artefatos
        uses: actions/download-artifact@v4
        with:
          path: results
          
      - name: ðŸ“Š Gerar resumo
        run: |
          echo "## ðŸ† Scraping TOP 10 Leiloeiros" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**ExecuÃ§Ã£o:** ${{ github.run_number }}" >> $GITHUB_STEP_SUMMARY
          echo "**Data:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -d "results" ]; then
            echo "### Arquivos gerados:" >> $GITHUB_STEP_SUMMARY
            find results -name "*.json" -exec basename {} \; >> $GITHUB_STEP_SUMMARY 2>/dev/null || echo "Nenhum arquivo JSON encontrado" >> $GITHUB_STEP_SUMMARY
          fi
